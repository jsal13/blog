{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title:  \"Byte Pair Encoding: A Byte-Sized Introduction\"\n",
    "date:   2022-01-23\n",
    "\n",
    "classes: wide\n",
    "\n",
    "header:\n",
    "  overlay_filter: rgba(0, 146, 202, 0.8)\n",
    "  overlay_image: /assets/images/title_compression_spring.jpg\n",
    "  caption: \"Photo Credit: [**Jean-Jacques Milan**](https://commons.wikimedia.org/wiki/File:Ressort_de_compression.jpg#metadata)\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "While going over some Natural Language Processing topics, I stumbled on the _byte pair encoding_ algorithm.  I thought that, given its usefulness in a number of NLP applications, that it'd be fairly complex and quite difficult to understand &mdash; but it turns out that it's pretty straight-forward!  Let's look into it a bit and give some examples.  First, our imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "**Problem:** We have a string (for now, let's say it's of lowercase letters) and we'd like to compress it; that is, we'd like to make the string shorter while containing the same information as before.\n",
    "\n",
    "Let's detail one potential solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aabaaabaaabaaadadaaa'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(12345)  # Set seed for reproducability.\n",
    "data = \"\".join(random.choices(\"abcd\", weights=[10, 5, 2, 1], k=20))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split this up into pairs of letters.  Then, we'll count to see how many times each pair comes up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aa', 9), ('ab', 3), ('ba', 3), ('ad', 2), ('da', 2)]\n"
     ]
    }
   ],
   "source": [
    "random.seed(12345)  # Set seed for reproducability.\n",
    "data = \"\".join(random.choices(\"abcd\", weights=[10, 5, 2, 1], k=20))\n",
    "\n",
    "# Split data up into pairs.  Each is a byte, so these are _Byte Pairs_.\n",
    "byte_pairs = [f\"{data[idx]}{data[idx + 1]}\" for idx in range(len(data) - 1)]\n",
    "byte_pair_counts = Counter(byte_pairs).most_common()\n",
    "\n",
    "print(byte_pair_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(_Note: when we do this, that we could also ignore the first letter to get an entirely different pairing.  It may be useful to try this to optimize the compression but, for now, let's stick with this._)\n",
    "\n",
    "We see that ``aa`` comes up quite a bit, followed by ``ba``and ``ab``.  Let's take the most common byte pair (``aa``) and replace it with a single letter that doesn't appear anywhere else in the data; for simplicity, let's use capital letters (Z, Y, X, ...) for replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aa', 'Z'), ('ab', 'Y'), ('ba', 'X'), ('ad', 'W'), ('da', 'V')]\n"
     ]
    }
   ],
   "source": [
    "# Make two functions here for reusability.\n",
    "def get_byte_pairs_from_data(data: str) -> list[tuple[str, int]]:\n",
    "    \"\"\"Get byte_pairs from most common to least common from ``data``.\"\"\"\n",
    "    byte_pairs = [f\"{data[idx]}{data[idx + 1]}\" for idx in range(len(data) - 1)]\n",
    "    return Counter(byte_pairs).most_common()\n",
    "\n",
    "\n",
    "def replace_byte_pair(data: str, pair: str, replacement: str) -> str:\n",
    "    \"\"\"Replace instances of ``pair``in ``data``in a serial manner.\"\"\"\n",
    "    while data.count(pair) > 0:\n",
    "        data = data.replace(pair, replacement, 1)  # Replace the first occurance.\n",
    "    return data\n",
    "\n",
    "\n",
    "# Now let's try them out!\n",
    "random.seed(12345)  # Set seed for reproducability.\n",
    "data = \"\".join(random.choices(\"abcd\", weights=[10, 5, 2, 1], k=20))\n",
    "byte_pair_counts = get_byte_pairs_from_data(data)\n",
    "\n",
    "# Make our replacement mapping / table.\n",
    "replacement_mapping = [\n",
    "    (byte_pair_counts[i][0], string.ascii_uppercase[::-1][i])\n",
    "    for i in range(len(byte_pair_counts))\n",
    "]\n",
    "print(replacement_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZbZabZabZadadZa'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens when we replace one value?\n",
    "replace_byte_pair(data, \"aa\", \"Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZbZYZYZWWZa\n",
      "\n",
      "No Compression: aaabbaaaaaabbaaaaaabbaaaaaaddaaddaaaaa\n",
      "Compression:    ZbZYZYZWWZa\n",
      "\n",
      "Original Length: 20\n",
      "Compressed Length: 11\n"
     ]
    }
   ],
   "source": [
    "# Let's replace all the values now!\n",
    "compressed_data = data[::]  # Copy data.\n",
    "for pair in replacement_mapping:\n",
    "    compressed_data = replace_byte_pair(compressed_data, pair[0], pair[1])\n",
    "\n",
    "print(compressed_data)\n",
    "\n",
    "print()\n",
    "print(\"No Compression: \" + \"\".join(byte_pairs))\n",
    "print(\"Compression:    \" + \"\".join(compressed_data))\n",
    "print()\n",
    "print(f\"Original Length: {len(data)}\\nCompressed Length: {len(compressed_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty good!  We can make this a bit larger if we'd like to see how good this compression works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length: 20000\n",
      "Compressed Length: 11281\n"
     ]
    }
   ],
   "source": [
    "random.seed(12345)  # Set seed for reproducability.\n",
    "data = \"\".join(random.choices(\"abcd\", weights=[10, 5, 2, 1], k=20_000))\n",
    "byte_pair_counts = get_byte_pairs_from_data(data)\n",
    "\n",
    "replacement_mapping = [\n",
    "    (byte_pair_counts[i][0], string.ascii_uppercase[::-1][i])\n",
    "    for i in range(len(byte_pair_counts))\n",
    "]\n",
    "\n",
    "compressed_data = data[::]  # Copy data.\n",
    "for pair in replacement_mapping:\n",
    "    compressed_data = replace_byte_pair(compressed_data, pair[0], pair[1])\n",
    "\n",
    "print(f\"Original Length: {len(data)}\\nCompressed Length: {len(compressed_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point, we'll need to decode this.  We can do this by looking at our replacement mapping and replacing in _the reverse order_ (first in, last out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompressed_data = compressed_data[::]  # Copy data.\n",
    "for pair in replacement_mapping[::-1]:\n",
    "    decompressed_data = replace_byte_pair(decompressed_data, pair[1], pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Got the same data back!\n",
    "print(data == decompressed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things To Notice\n",
    "\n",
    "First, there is a lot of room for optimization in the algorithm above: I've attempted to make the algorithm a bit more readable at the cost of optimization.  Optimization of the above is left as an exercise to the reader.\n",
    "\n",
    "Second, we don't gain a whole lot by replacing pairs that don't occur frequently (especially those which occur once), so it's possible to remove them.  It's also possible to do this process recursively on an encoded set of data to get a bit more compression.  For example, if we encoded a string to ``ZaYaZaZZ`` we might see that ``Za`` occurs a few times and want to compress this down further to, say, ``XYaXZZ``.  This may not seem significant in this case, but it may save a lot of space for extremely large, repetitive files.\n",
    "\n",
    "## Can we do this with anything besides strings of letters?\n",
    "\n",
    "Sure.  One common thing to do in Natural Language Processing is to pair adjacent words into \"bigrams\": for example, \"Mary Had A Little Lamb\" goes to ``[(\"Mary\", \"Had\"), (\"Had\", \"A\"), (\"A\", \"Little\"), (\"Little\", \"Lamb\")]``.  From here, we can see how we might apply the above techniques.  For this sentence there is no better encoding, but one can imagine a long novel or logfiles with a significant amount of text repetition where this would compress the original data quite a bit."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "409c0ef82ba8b7e64c8e82f82fa10040b189117e3f7cf50921b9ec62b5d5a915"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('blog-Mz1OaUtd-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
