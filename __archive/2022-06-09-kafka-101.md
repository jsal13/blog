---
title:  "Kafka 101: Messing with Kafka Locally in Docker Compose"
date:   2022-06-09

toc: true
header:
  overlay_filter: rgba(0, 146, 202, 0.8)
  overlay_image: /assets/images/title-kafka-101.jpg
  caption: "Photo Credit: [**This Site**](https://so.unansea.com/gregor-samsa-geesiga-ah-novel-ah-metamorphosis-the/)"
---

## Kafka 101

This will briefly detail my adventures into learning Kafka by running it locally and messing with it.

## Getting Kafka

Docker-compose felt like the easiest way to get Kafka running, so I used the associated docker-compose file from [Confluent](https://developer.confluent.io/quickstart/kafka-docker/) to quickly get one up and running.

There's a few things in the docker-compose file, so let's go through what all of those do.

### ZooKeeper

Despite having one of the worst logos on Apache (_Commando meets Kingdom Hearts_), ZooKeeper is an important tool for a number of other tools.  Let's see how ZooKeeper's apache page describes it:

> ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.

Hm, what does this mean?  It's fairly general sounding.  Let's see what Wikipedia says about it.

> ZooKeeper is essentially a service for distributed systems offering a hierarchical key-value store, which is used to provide a distributed configuration service, synchronization service, and naming registry for large distributed systems\[.\]

Alright, so this is a service which offers some nice sync and configuration services to a bunch of things.  Let's make this more concrete by asking: how does Kafka use ZooKeeper?  From [this source](https://www.cloudkarafka.com/blog/cloudkarafka-what-is-zookeeper.html) we learn that ZooKeeper is used in a few different places:

- **Controller Election**: organizing the nodes so that if one is shut down, the controller can tell the replicas to elect a new controller and make sure the other nodes agree to follow this new controller.

- **Configuration of Topics**: organizes the metadata for topics, including the list of existing topics, location of all replicas, config overrides, etc.

- **Access Control Lists**: List of ACLs for all topics are maintained.

- **Membership of the Cluster**: List of all brokers that are part of the cluster.

Alright, so that's a lot of book-keeping that ZooKeeper is doing.  While it is not (anymore) necessary to have ZooKeeper, Confluent notes that using any other option is not yet production-ready.  We'll stick to the basics and use ZooKeeper.

### Kafka Broker

The broker is similar to a broker in trading: it allows for consumers to access things which are being produced.  In Kafka, this allows consumers to fetch messages by topic, partition, and offset.  It can also create clusters (sharing info using ZooKeeper). Each cluster has one broker, which acts as the controller.

## ZooKeeper and Broker are Running, Now What?

We've got a few things to try out.

### Creating a Topic with the Broker

Let's go into the broker and create a topic.

```bash
docker exec -it broker /bin/bash
```

Now that we're in here, let's use the following command to create a topic:

```bash
kafka-topics --bootstrap-server broker:9092 \
             --create \
             --topic quickstart
```

`Created topic quickstart.`  Awesome.  We've created our topic.

### Producing Messages on the Topic

While still in the broker container, let's produce some messages.  We can do this using the `kafka-console-producer`:

```bash
kafka-console-producer --bootstrap-server broker:9092 \
                       --topic quickstart
```

We get a small terminal here denoted by some `>`'s.  Let's type in "Hello" and then "World" and see what happens.

Nothing.

Well, that's to be expected: nothing is consuming them!

### Consuming Messages

Let's go into another terminal tab and exec into the container again.

```bash
docker exec -it broker /bin/bash
```

We'll type the following command to create a consumer...

```bash
docker exec --interactive --tty broker \
kafka-console-consumer --bootstrap-server broker:9092 \
                       --topic quickstart \
                       --from-beginning
```

And we get the following output:

```bash
[appuser@e7e3e3f532e0 ~]$ kafka-console-consumer --bootstrap-server broker:9092 --topic quickstart --from-beginning
hello
world
```

Wow!  Awesome!

What if we were to go back to our producer tab and write some more messages?  If we do so, we see that they quickly show up in the consumer!  Cool.
